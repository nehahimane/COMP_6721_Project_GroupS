{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC4iKtnO48wG",
        "outputId": "14b6e8af-4bf1-4483-c7a2-288f0af741bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5fHbmIpJ5ddh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/AI/Datasets\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZofQw776Glp",
        "outputId": "7c1dfdda-1535-4d10-8f33-354e76787f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI/Datasets\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AI/Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtcyEQNd6HVQ",
        "outputId": "655bfc09-a889-4fdd-d812-7f04f68e203f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fercustomdataset-3classes.zip to /content/drive/MyDrive/AI/Datasets\n",
            " 96% 80.0M/83.1M [00:03<00:00, 35.7MB/s]\n",
            "100% 83.1M/83.1M [00:03<00:00, 25.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d nightfury007/fercustomdataset-3classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gxMzgZrg6LS6"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "for file in os.listdir():\n",
        "    if file.endswith(\".zip\"):\n",
        "        with zipfile.ZipFile(file, \"r\") as zip_file:\n",
        "            zip_file.extractall()\n",
        "        os.remove(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yIDNx91q6OEl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import glob\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import cv2\n",
        "import torchvision.datasets as datasets\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jDL2XD2n6TVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83c5091-4c30-4450-d4db-8aed7988b3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Disappointed', 'interested', 'neutral']\n"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/drive/MyDrive/AI/Datasets/FER_Custom_Dataset'\n",
        "IMAGE_DIM=256\n",
        "\n",
        "print(os.listdir(data_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CWrqO8h56VYk"
      },
      "outputs": [],
      "source": [
        "def load_data(path, test_split, batch_size, input_size, shuffle_dataset=True,random_seed=42):\n",
        "    \n",
        "    transform_dict ={'src': transforms.Compose([transforms.Grayscale(3),\n",
        "                                                transforms.Resize(IMAGE_DIM),\n",
        "                                                transforms.CenterCrop(224), \n",
        "                                                transforms.RandomHorizontalFlip(), \n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                     std=[0.229, 0.224, 0.225]\n",
        "                                                                    )\n",
        "                                               ]\n",
        "                                              )\n",
        "                    }\n",
        "    \n",
        "    dataset = datasets.ImageFolder(data_dir, transform=transform_dict.get('src'))\n",
        "    dataset_size = len(dataset)\n",
        "    train_test_indices = list(range(dataset_size))\n",
        "    test_split = int(np.floor(test_split * dataset_size))\n",
        "    \n",
        "    if shuffle_dataset :\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(train_test_indices)\n",
        "    train_indices, test_indices = train_test_indices[test_split:], train_test_indices[:test_split]\n",
        "    \n",
        "\n",
        "    # Creating PT data samplers and loaders:\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "    data_loader_train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                              sampler=train_sampler)\n",
        "    data_loader_test = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                    sampler=test_sampler)\n",
        "    \n",
        "    return data_loader_train, data_loader_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sJcMFe_H6Ye2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424af3b4-7a97-430a-e898-a5308207feb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1096 274\n"
          ]
        }
      ],
      "source": [
        "train_loader, test_loader=load_data(data_dir,0.2,32,(64,64))\n",
        "\n",
        "print(len(train_loader), len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HnLT4T0Q6ZbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773a684c-fffb-4406-c180-1b0b759cd994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "######## Write your code here ##############\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=False)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7VLVATHA6bld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b3d961-4ab7-4844-cd2d-bf16f1bbb1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Epoch [1/3], Step [100/1096], Loss: 1.0960, Accuracy: 53.12%\n",
            "Epoch [1/3], Step [200/1096], Loss: 1.0912, Accuracy: 37.50%\n",
            "Epoch [1/3], Step [300/1096], Loss: 1.0709, Accuracy: 46.88%\n",
            "Epoch [1/3], Step [400/1096], Loss: 1.1369, Accuracy: 31.25%\n",
            "Epoch [1/3], Step [500/1096], Loss: 1.0830, Accuracy: 40.62%\n",
            "Epoch [1/3], Step [600/1096], Loss: 1.0620, Accuracy: 50.00%\n",
            "Epoch [1/3], Step [700/1096], Loss: 1.1617, Accuracy: 28.12%\n",
            "Epoch [1/3], Step [800/1096], Loss: 1.1140, Accuracy: 34.38%\n",
            "Epoch [1/3], Step [900/1096], Loss: 1.0979, Accuracy: 34.38%\n",
            "Epoch [1/3], Step [1000/1096], Loss: 1.0805, Accuracy: 46.88%\n",
            "Epoch [2/3], Step [100/1096], Loss: 1.1858, Accuracy: 21.88%\n",
            "Epoch [2/3], Step [200/1096], Loss: 1.1621, Accuracy: 21.88%\n",
            "Epoch [2/3], Step [300/1096], Loss: 1.0894, Accuracy: 40.62%\n",
            "Epoch [2/3], Step [400/1096], Loss: 1.0539, Accuracy: 43.75%\n",
            "Epoch [2/3], Step [500/1096], Loss: 1.0642, Accuracy: 46.88%\n",
            "Epoch [2/3], Step [600/1096], Loss: 1.0469, Accuracy: 43.75%\n",
            "Epoch [2/3], Step [700/1096], Loss: 1.0535, Accuracy: 50.00%\n",
            "Epoch [2/3], Step [800/1096], Loss: 0.9932, Accuracy: 62.50%\n",
            "Epoch [2/3], Step [900/1096], Loss: 1.0425, Accuracy: 46.88%\n",
            "Epoch [2/3], Step [1000/1096], Loss: 1.1259, Accuracy: 18.75%\n",
            "Epoch [3/3], Step [100/1096], Loss: 1.0031, Accuracy: 56.25%\n",
            "Epoch [3/3], Step [200/1096], Loss: 1.0753, Accuracy: 50.00%\n",
            "Epoch [3/3], Step [300/1096], Loss: 1.1501, Accuracy: 18.75%\n",
            "Epoch [3/3], Step [400/1096], Loss: 1.1235, Accuracy: 31.25%\n",
            "Epoch [3/3], Step [500/1096], Loss: 1.0631, Accuracy: 40.62%\n",
            "Epoch [3/3], Step [600/1096], Loss: 1.0750, Accuracy: 43.75%\n",
            "Epoch [3/3], Step [700/1096], Loss: 1.0617, Accuracy: 37.50%\n",
            "Epoch [3/3], Step [800/1096], Loss: 1.0492, Accuracy: 50.00%\n",
            "Epoch [3/3], Step [900/1096], Loss: 1.0352, Accuracy: 53.12%\n",
            "Epoch [3/3], Step [1000/1096], Loss: 1.0558, Accuracy: 40.62%\n",
            "######## Training Finished in 2111.2282972335815 seconds ###########\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 3\n",
        "total_steps = len(train_loader)\n",
        "t1 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            \n",
        "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ha_rDvC6di2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NTcIdKW5PPV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}