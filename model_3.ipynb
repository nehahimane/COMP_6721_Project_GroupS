{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnIt6atwgzxFESzrzuuDSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehahimane/COMP_6721_Project_GroupS/blob/AI_Hardik/model_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC4iKtnO48wG",
        "outputId": "1cc0cfa0-8a9d-4b83-8f97-e9c35e3e5d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/AI_Datasets\""
      ],
      "metadata": {
        "id": "5fHbmIpJ5ddh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AI_Datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZofQw776Glp",
        "outputId": "4640c1f3-2ba4-4b11-a748-0ac04c34afce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI_Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nightfury007/fercustomdataset-3classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtcyEQNd6HVQ",
        "outputId": "1374936b-3467-40db-e216-685e212dd96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fercustomdataset-3classes.zip to /content/drive/MyDrive/AI_Datasets\n",
            "100% 83.0M/83.1M [00:00<00:00, 159MB/s]\n",
            "100% 83.1M/83.1M [00:00<00:00, 142MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "for file in os.listdir():\n",
        "    if file.endswith(\".zip\"):\n",
        "        with zipfile.ZipFile(file, \"r\") as zip_file:\n",
        "            zip_file.extractall()\n",
        "        os.remove(file)"
      ],
      "metadata": {
        "id": "gxMzgZrg6LS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import glob\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import cv2\n",
        "import torchvision.datasets as datasets\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "yIDNx91q6OEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/AI_Datasets/FER_Custom_Dataset'\n",
        "IMAGE_DIM=224\n",
        "\n",
        "print(os.listdir(data_dir))"
      ],
      "metadata": {
        "id": "jDL2XD2n6TVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f08ed1-9a9c-4091-c5e9-6922fabf402d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Disappointed', 'interested', 'neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path, test_split, batch_size, input_size, shuffle_dataset=True,random_seed=42):\n",
        "    \n",
        "    transform_dict ={'src': transforms.Compose([transforms.Resize(IMAGE_DIM),\n",
        "                                                transforms.ToTensor(),\n",
        "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                                     std=[0.229, 0.224, 0.225]\n",
        "                                                                    )\n",
        "                                               ]\n",
        "                                              )\n",
        "                    }\n",
        "    \n",
        "    dataset = datasets.ImageFolder(data_dir, transform=transform_dict.get('src'))\n",
        "    dataset_size = len(dataset)\n",
        "    train_test_indices = list(range(dataset_size))\n",
        "    test_split = int(np.floor(test_split * dataset_size))\n",
        "    \n",
        "    if shuffle_dataset :\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(train_test_indices)\n",
        "    train_indices, test_indices = train_test_indices[test_split:], train_test_indices[:test_split]\n",
        "    \n",
        "\n",
        "    # Creating PT data samplers and loaders:\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "    data_loader_train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                              sampler=train_sampler)\n",
        "    data_loader_test = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                    sampler=test_sampler)\n",
        "    \n",
        "    return data_loader_train, data_loader_test"
      ],
      "metadata": {
        "id": "CWrqO8h56VYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader=load_data(data_dir,0.2,32,(64,64))\n",
        "\n",
        "print(len(train_loader), len(test_loader))"
      ],
      "metadata": {
        "id": "sJcMFe_H6Ye2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985958f5-28ac-4aa1-c999-e1cf7492d42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1096 274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## Write your code here ##############\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=False)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "HnLT4T0Q6ZbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb3f17c-aa4f-4893-fdb7-9b383b8ba92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: {}\".format(device))\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 1\n",
        "total_steps = len(train_loader)\n",
        "t1 = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        print(i)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backprop and optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Train accuracy\n",
        "        total = labels.size(0)\n",
        "        _,predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item(),\n",
        "                    (correct / total) * 100))\n",
        "            \n",
        "print(\"######## Training Finished in {} seconds ###########\".format(time.time()-t1))"
      ],
      "metadata": {
        "id": "7VLVATHA6bld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fe6674-494c-45d5-c2e5-c789dcd8d9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "Epoch [1/1], Step [10/1096], Loss: 5.7729, Accuracy: 18.75%\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "Epoch [1/1], Step [20/1096], Loss: 2.0750, Accuracy: 21.88%\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "Epoch [1/1], Step [30/1096], Loss: 1.3226, Accuracy: 28.12%\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "Epoch [1/1], Step [40/1096], Loss: 1.0701, Accuracy: 46.88%\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "Epoch [1/1], Step [50/1096], Loss: 1.1453, Accuracy: 31.25%\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "Epoch [1/1], Step [60/1096], Loss: 1.1285, Accuracy: 34.38%\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "Epoch [1/1], Step [70/1096], Loss: 1.1802, Accuracy: 25.00%\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "Epoch [1/1], Step [80/1096], Loss: 1.1267, Accuracy: 34.38%\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "Epoch [1/1], Step [90/1096], Loss: 1.1361, Accuracy: 25.00%\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "Epoch [1/1], Step [100/1096], Loss: 1.0870, Accuracy: 43.75%\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "Epoch [1/1], Step [110/1096], Loss: 1.1118, Accuracy: 34.38%\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "Epoch [1/1], Step [120/1096], Loss: 1.0959, Accuracy: 34.38%\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "Epoch [1/1], Step [130/1096], Loss: 1.0213, Accuracy: 62.50%\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "Epoch [1/1], Step [140/1096], Loss: 1.1170, Accuracy: 25.00%\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "Epoch [1/1], Step [150/1096], Loss: 1.1665, Accuracy: 28.12%\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "Epoch [1/1], Step [160/1096], Loss: 1.1768, Accuracy: 25.00%\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "Epoch [1/1], Step [170/1096], Loss: 1.1165, Accuracy: 28.12%\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "Epoch [1/1], Step [180/1096], Loss: 1.0847, Accuracy: 31.25%\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "Epoch [1/1], Step [190/1096], Loss: 1.1033, Accuracy: 40.62%\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "Epoch [1/1], Step [200/1096], Loss: 1.1135, Accuracy: 31.25%\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "Epoch [1/1], Step [210/1096], Loss: 1.0549, Accuracy: 53.12%\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "Epoch [1/1], Step [220/1096], Loss: 1.1042, Accuracy: 34.38%\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "Epoch [1/1], Step [230/1096], Loss: 1.1002, Accuracy: 40.62%\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "Epoch [1/1], Step [240/1096], Loss: 1.1081, Accuracy: 37.50%\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "Epoch [1/1], Step [250/1096], Loss: 1.0907, Accuracy: 37.50%\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "Epoch [1/1], Step [260/1096], Loss: 1.0836, Accuracy: 46.88%\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "Epoch [1/1], Step [270/1096], Loss: 1.1131, Accuracy: 34.38%\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "Epoch [1/1], Step [280/1096], Loss: 1.1165, Accuracy: 31.25%\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "Epoch [1/1], Step [290/1096], Loss: 1.0702, Accuracy: 59.38%\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "Epoch [1/1], Step [300/1096], Loss: 1.0661, Accuracy: 56.25%\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "Epoch [1/1], Step [310/1096], Loss: 1.1252, Accuracy: 37.50%\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "Epoch [1/1], Step [320/1096], Loss: 1.1171, Accuracy: 25.00%\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ha_rDvC6di2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}